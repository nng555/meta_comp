{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59882c0f",
   "metadata": {},
   "source": [
    "### Training VAEs\n",
    "\n",
    "Running the Train Script: \n",
    "- Script: celeba/train.py\n",
    "- Launch one job: sbatch simple_launch.sbatch   \n",
    "- Launch multiple: sh loop.sh\n",
    "\n",
    "Getting the trained VAE Checkpoints: \n",
    "- Trained VAE Checkpoints: '/checkpoints_loss_checks/MN_2/' \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1178f09e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Making the Metadataset\n",
    "\n",
    "Loading the trained VAE Checkpoints: \n",
    "- Trained VAE Checkpoints: '/checkpoints_loss_checks/MN_2/< model_name >_e29.pt' \n",
    "\n",
    "Generate vae samples: \n",
    "- Script: celeba/generate_vae_samples.py\n",
    "- Launch: sh launch_playground.sh  # uncomment example \n",
    "- Saved: /scratch/mr7401/vaes/generations/MN_2/< model_name >/samples/ < id >.pt\n",
    "\n",
    "Calculate and Save Log Likelihoods: \n",
    "- Script: celeba/calculate_log_likelihoods.py\n",
    "- Launch: sh launch_playground.sh  # uncomment example\n",
    "- Saved: /scratch/mr7401/vaes/likelihoods/2/< model_name >/log_liklihood.jsonl\n",
    "\n",
    "Make VIT encodings: \n",
    "- Script: celeba/generate_vae_encodings.py\n",
    "- Launch: sh launch_playground.sh  # uncomment example\n",
    "- Saved: /scratch/mr7401/vaes/generations/MN_2/< model_name >/encodings/ < id >.pt \n",
    "- Combined version: /scratch/mr7401/vaes/generations/MN_2/< model_name >/encodings/all_encodings.pt\n",
    "\n",
    "Make the metadataset: \n",
    "- I did this a notebook. I copied the code below if you want to see it. Please change the paths before running so as to not overwrite the files. You can also run with save=False to not write any files. \n",
    "- full set of sample information: /scratch/mr7401/meta_comp_data/vaes/metadatasets/MN_2/metadataset.csv\n",
    "\n",
    "- Saved metadataset training data: these are the paths for n_per_set = 5 and n_samples = 10,000 which is what we used for training. \n",
    "    - train: /scratch/mr7401/meta_comp_data/vaes/metadatasets/MN_2/5_100000/train_seed_0.pt, \n",
    "    - train_metadata =/scratch/mr7401/meta_comp_data/vaes/metadatasets/MN_2/5_100000/train_seed_0.pt\n",
    "\n",
    "- Save metadataset test data: the training script looks for everything in the following folder: \n",
    "    - /scratch/mr7401/meta_comp_data/vaes/metadatasets/MN_2/5_2000/ \n",
    "    - e.g. files would be like 'test_one_ood_models_128_748_seed_2.pt'. This made it easier to run evals for particular model pairs. \n",
    "    - test_one_ood_models refers to 1 ID model vs 1 OOD model. \n",
    "    - test_both_ood_models refers to 2 OOD models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1cfc6b",
   "metadata": {},
   "source": [
    "### Training the Meta-Model \n",
    "\n",
    "- Script: celeba/train_meta_model.py\n",
    "- Launch: sh loop.sh, which loops over learning rates, calling simple_launch.sbatch while passing in the learning rate as an exported environment variable. \n",
    "- Trained Meta-Models: '/checkpoints_ls/MN_2/5_10000/< wandb_run > -mse_dir/ epoch_checkpoints / epoch_5.pt' \n",
    "- There is also supposed to be a predictions file and losses file saved in that directory, but they crashed when I last ran it. I assume out of memory. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369bfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Make Meta-Datasets ##############\n",
    "import os \n",
    "import pandas as pd \n",
    "import random \n",
    "import torch \n",
    "import pickle\n",
    "\n",
    "def mean(lst): \n",
    "    return sum(lst) / len(lst)\n",
    "    \n",
    "def calculate_kl_diff(m1_m1_ll, m1_m2_ll, m2_m1_ll, m2_m2_ll):\n",
    "    kldiff = -(mean(m1_m1_ll) + mean(m1_m2_ll) + mean(m2_m1_ll) + mean(m2_m2_ll))\n",
    "    return kldiff\n",
    "\n",
    "def get_encodings(encodings_mappings, source_model, ids = []):\n",
    "    encoding_map = encodings_mappings[source_model]\n",
    "    indexes = [encoding_map[\"ids\"].index(item) for item in ids] \n",
    "    encodings = [encoding_map[\"embeddings\"][i] for i in indexes] #[tensor]\n",
    "    r = torch.stack(encodings) # tensor[batch_size, dim]\n",
    "    return r\n",
    "\n",
    "def generate_meta_dataset(samples, n_samples, n_per_set, save = True, seed = 42, save_dir = \"/\", models_to_include = [], set_name = \"other\", verbose = False):\n",
    "    # Initialize an empty list to store the train dataset\n",
    "    m1_ids = []\n",
    "    m2_ids = []\n",
    "    m1s = []\n",
    "    m2s = []\n",
    "\n",
    "    x1_data = []\n",
    "    x2_data = []\n",
    "    y_data = []\n",
    "\n",
    "    if models_to_include:\n",
    "        print(f\"Filtering for only models in list: {models_to_include}\")\n",
    "        samples = samples[samples[\"gen_source_model\"].isin(models_to_include)]\n",
    "    source_models = list(samples['gen_source_model'].unique())\n",
    "    encodings_mappings = {} # model name: {embeddings: [], ids: []}\n",
    "    \n",
    "    for model_name in source_models: \n",
    "        combined_encodings_path = samples[samples[\"gen_source_model\"] == model_name][\"combined_encodings_location\"].iloc[0]\n",
    "        encodings_mappings[model_name] = torch.load(combined_encodings_path)\n",
    "    \n",
    "    print(f\"Starting Metadaset Generation...\")\n",
    "\n",
    "    random.seed(seed)\n",
    "    # Generate n samples\n",
    "    for i in range(n_samples):\n",
    "        # Randomly select 2 models to compare\n",
    "        if i % 100 == 0: \n",
    "            print(f\"Completed: {i}\", flush = True)\n",
    "        \n",
    "        model1, model2 = random.sample(source_models, 2)\n",
    "        if verbose: \n",
    "            print(f\"Selected: {model1}, {model2}\")\n",
    "        \n",
    "        # Select 5 samples for each model\n",
    "        model1_samples = samples[samples['gen_source_model'] == model1].sample(n_per_set, random_state=seed)\n",
    "        model2_samples = samples[samples['gen_source_model'] == model2].sample(n_per_set, random_state=seed)\n",
    "        if verbose: \n",
    "            print(f\"Samples: \\n{model1_samples[\"id\"].to_list()}, \\n{model2_samples[\"id\"].to_list()}\")\n",
    "        \n",
    "        # Get encodings \n",
    "        sample1_encodings = get_encodings(encodings_mappings = encodings_mappings, source_model = model1, ids = model1_samples[\"id\"].tolist()) \n",
    "        sample2_encodings = get_encodings(encodings_mappings = encodings_mappings, source_model = model2, ids = model2_samples[\"id\"].tolist()) \n",
    "        \n",
    "        # Get label \n",
    "        m1_m1_ll, m1_m2_ll = model1_samples[f\"{model1}_ll\"].to_list(), model1_samples[f\"{model2}_ll\"].to_list()\n",
    "        m2_m1_ll, m2_m2_ll = model2_samples[f\"{model1}_ll\"].to_list(), model2_samples[f\"{model2}_ll\"].to_list()\n",
    "        kldiff = calculate_kl_diff(m1_m1_ll, m1_m2_ll, m2_m1_ll, m2_m2_ll)\n",
    "    \n",
    "        # add to sets for saving \n",
    "        m1_ids.append(model1_samples[\"id\"].tolist())\n",
    "        m2_ids.append(model2_samples[\"id\"].tolist())\n",
    "        \n",
    "        m1s.append([model1] * len(model1_samples))\n",
    "        m2s.append([model2] * len(model2_samples))\n",
    "        \n",
    "        x1_data.append(sample1_encodings)\n",
    "        x2_data.append(sample2_encodings)\n",
    "        y_data.append(kldiff)\n",
    "    \n",
    "    x1_stacked = torch.stack(x1_data)\n",
    "    x2_stacked = torch.stack(x2_data)\n",
    "    y_stacked = torch.tensor(y_data)\n",
    "    sample_indexes = torch.arange(n_samples)\n",
    "\n",
    "    # Make objects\n",
    "    dataset = {\"x1\": x1_stacked, \"x2\": x2_stacked, \"y\": y_stacked, \"sample_index\": sample_indexes} # can move to/ from GPU, shuffled.\n",
    "    metadata = {\"sample_index\": sample_indexes, \"m1_ids\": m1_ids, \"m2_ids\": m2_ids, \"m1s\": m1s, \"m2s\": m2s} # use the sample_indexes to get the metadata. \n",
    "\n",
    "    if save: \n",
    "        os.makedirs(f\"{save_dir}/{n_per_set}_{n_samples}\", exist_ok = True)\n",
    "        dataset_save_path = f\"{save_dir}/{n_per_set}_{n_samples}/{set_name}_seed_{seed}.pt\"\n",
    "        metadata_save_path = f\"{save_dir}/{n_per_set}_{n_samples}/{set_name}_metadata_seed_{seed}.pkl\"\n",
    "        \n",
    "        torch.save(dataset, dataset_save_path)\n",
    "        with open(metadata_save_path, \"wb\") as f:\n",
    "            pickle.dump(metadata, f)\n",
    "        print(f\"Saved to {dataset_save_path} and {metadata_save_path}\")\n",
    "        \n",
    "    return dataset, metadata \n",
    "\n",
    "test_models = ['vae_ldim_4', 'vae_ldim_1384', 'vae_ldim_748',  'vae_ldim_2048']\n",
    "    \n",
    "train_models = [\n",
    " 'vae_ldim_8',\n",
    " 'vae_ldim_16',\n",
    " 'vae_ldim_32',\n",
    " 'vae_ldim_64',\n",
    " 'vae_ldim_128',\n",
    " 'vae_ldim_256',\n",
    " 'vae_ldim_512',\n",
    " 'vae_ldim_718',\n",
    " 'vae_ldim_1024'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65477596",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Make Train Datasets ##########\n",
    "\n",
    "# This is all of the samples, including the encoding location, ids, and log likelihoods. \n",
    "samples = pd.read_csv(f\"/scratch/mr7401/meta_comp_data/vaes/metadatasets/MN_2/metadataset.csv\", index_col = 0)\n",
    "\n",
    "for n_per_set in [5,10,20,30]:\n",
    "    for seed in [0,1,2]:\n",
    "        data, metadata = generate_meta_dataset(\n",
    "            samples, \n",
    "            n_samples=10000,\n",
    "            n_per_set = n_per_set, \n",
    "            seed = seed, \n",
    "            models_to_include = train_models, \n",
    "            save = False , \n",
    "            set_name = \"train\", \n",
    "            save_dir = \"/scratch/mr7401/meta_comp_data/vaes/metadatasets/MN_2\", \n",
    "            verbose = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ddf095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############ Generate test datasets ##################\n",
    "from itertools import combinations\n",
    "\n",
    "train_models = [\n",
    " 'vae_ldim_8',\n",
    " 'vae_ldim_16',\n",
    " 'vae_ldim_32',\n",
    " 'vae_ldim_64',\n",
    " 'vae_ldim_128',\n",
    " 'vae_ldim_256',\n",
    " 'vae_ldim_512',\n",
    " 'vae_ldim_718',\n",
    " 'vae_ldim_1024'\n",
    "]\n",
    "\n",
    "test_models = ['vae_ldim_4', 'vae_ldim_1384', 'vae_ldim_748',  'vae_ldim_2048']\n",
    "\n",
    "# ### OOD: test vs test \n",
    "for model1, model2 in combinations(test_models, 2):\n",
    "    print(f\"Pairing: {model1} vs {model2}\")\n",
    "    dim1 = model1.split(\"_\")[-1]\n",
    "    dim2 = model2.split(\"_\")[-1]\n",
    "    for n_per_set in [5]: #,10,20,30]:\n",
    "        for seed in [2]:\n",
    "            data, metadata = generate_meta_dataset(\n",
    "                samples, \n",
    "                n_samples=2000,\n",
    "                n_per_set = n_per_set, \n",
    "                seed = seed, \n",
    "                models_to_include = [model1, model2], \n",
    "                save = False, \n",
    "                set_name = f\"test_both_ood_models_{dim1}_{dim2}\", \n",
    "                save_dir = \"/scratch/mr7401/meta_comp_data/vaes/metadatasets/MN_2\", \n",
    "                verbose = False\n",
    "            )\n",
    "\n",
    "# ### OOD mixed: train vs test \n",
    "for model1 in train_models: \n",
    "    for model2 in test_models: \n",
    "        print(f\"Pairing: {model1} vs {model2}\")\n",
    "        dim1 = model1.split(\"_\")[-1]\n",
    "        dim2 = model2.split(\"_\")[-1]\n",
    "        for n_per_set in [5]: #,10,20,30]:\n",
    "            for seed in [2]:\n",
    "                data, metadata = generate_meta_dataset(\n",
    "                    samples, \n",
    "                    n_samples=2000,\n",
    "                    n_per_set = n_per_set, \n",
    "                    seed = seed, \n",
    "                    models_to_include = [model1, model2], \n",
    "                    save = False, \n",
    "                    set_name = f\"test_one_ood_models_{dim1}_{dim2}\", \n",
    "                    save_dir = \"/scratch/mr7401/meta_comp_data/vaes/metadatasets/MN_2\", \n",
    "                    verbose = False\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
